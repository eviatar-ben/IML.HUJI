{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lab 10 - Principal Component Analysis\n",
    "\n",
    "The purpose of the following lab is to investigate the work of the PCA algorithm on a set of 3 datasets\n",
    "- Sample of 2500 data-points drawn from a multivariate Gaussian with a diagonal covariance matrix with different variances.\n",
    "- Sample of 1000 data-points sampled on the $\\ell_2$ unit circle and then randomly rotated in $\\mathbb{R}^3$\n",
    "- A simple real-world dataset of arrests in the United States.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10792/1042593450.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\eviatar\\Study\\YearD\\semester b\\I.M.L\\repo\\IML.HUJI\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Imports and settings for plotting of graphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objects\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_subplots\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ],
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error"
    }
   ],
   "source": [
    "import sys \n",
    "sys.path.append(\"../\")\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ortho_group\n",
    "from sklearn.decomposition import PCA\n",
    "np.random.seed(1)\n",
    "\n",
    "color_scheme = [\"rgb(189,6,96)\", \"rgb(6,189,99)\", \"rgb(6,96,189)\"]\n",
    "\n",
    "def plot_principal_component(pca, i):\n",
    "    # Get PC representation as a subspace with size proportional to the corresponding singular value\n",
    "    size = np.sqrt(pca.singular_values_[i])\n",
    "    pc = np.outer(pca.components_[i], np.array([-1,1])) * size\n",
    "\n",
    "    return go.Scatter3d(x=pc[0], y=pc[1], z=pc[2], mode=\"lines\", opacity=.5,\n",
    "                        line=dict(color=color_scheme[i], width=2*size), name='PC {}'.format(i+1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run one of the code cells below to load the desired dataset and relevant settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Multivariate Gaussian\n",
    "cov = [3, 0, 0], [0, 1, 0], [0, 0, 0.1]\n",
    "X = np.random.multivariate_normal([0, 0, 0], cov, size=2500) @ ortho_group.rvs(3, random_state=1)\n",
    "scene = proj_scene = dict(xaxis=dict(range=[-4, 4]), yaxis=dict(range=[-4, 4]), zaxis=dict(range=[-4, 4]), \n",
    "             camera=dict(eye=dict(x=1.5, y=1.5, z=.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10792/3778929392.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Circular data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mortho_group\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m scene = proj_scene = dict(xaxis=dict(range=[-1.5, 1.5]), yaxis=dict(range=[-1.5, 1.5]), zaxis=dict(range=[-1.5, 1.5]), \n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# Circular data\n",
    "X = np.random.normal(size=(2, 1000))\n",
    "X = np.c_[(X/ np.linalg.norm(X, axis=0)).T, np.random.normal(0, .1, 1000)]\n",
    "X = X @ ortho_group.rvs(3, random_state=1)\n",
    "scene = proj_scene = dict(xaxis=dict(range=[-1.5, 1.5]), yaxis=dict(range=[-1.5, 1.5]), zaxis=dict(range=[-1.5, 1.5]), \n",
    "             camera=dict(eye=dict(x=-1.5, y=-1.5, z=.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10792/1790883071.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Real-world data: US Arrests\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../datasets/USArrests.data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"UrbanPop\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m scene = dict(xaxis=dict(range=[-10,10]), yaxis=dict(range=[-130,170]), zaxis=dict(range=[-20,30]), \n\u001b[0;32m      5\u001b[0m              camera=dict(eye=dict(x=2, y=-2, z=.4)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# Real-world data: US Arrests\n",
    "X = pd.read_csv(\"../datasets/USArrests.data\", index_col=0).drop(\"UrbanPop\", axis=1).to_numpy()\n",
    "X = (X - X.mean(axis=0))\n",
    "scene = dict(xaxis=dict(range=[-10,10]), yaxis=dict(range=[-130,170]), zaxis=dict(range=[-20,30]), \n",
    "             camera=dict(eye=dict(x=2, y=-2, z=.4)))\n",
    "proj_scene = dict(xaxis=dict(range=[-130,170]), yaxis=dict(range=[-20,20]), zaxis=dict(range=[-5,10]), \n",
    "             camera=dict(eye=dict(x=2, y=-2, z=.4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection Using PCA\n",
    "Let us begin with visualizing the original dataset as well as the PC components determined by the algorithm. In Figure 1, we can see the spread of the dataset in $\\mathbb{R}^3$, and that though it is represented in a 3 dimensional space, it is mostly described along some 2 dimensional space. \n",
    "\n",
    "Looking at the PCs, and specifically at their size and width, we get an understandment of \"how much\" of the data is spread in each direction.\n",
    "\n",
    "Rotate Figure 1 to view the data in two ways. Firstly view the data in an angle perpendicular to both PC1 and PC2. This will be the angle that the data has the largest amount of spread in a 2 dimensional subspace. See how for both the Gaussian and Circular datasets we are still able to see the main trends of the data. Next, view the data in an angle perpendicular to PC3. In this direction of the 3 dimentional space we are not able to get a clear view of the main trends of the data. We merly observe a dense cloud of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10792/2797261725.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpca\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m go.Figure(data = [go.Scatter3d(x = X[:, 0], y=X[:, 1], z=X[:, 2], opacity = .75, mode = 'markers', \n\u001b[0;32m      4\u001b[0m                                marker=dict(size=3, color=\"black\"), showlegend=False)] + \n\u001b[0;32m      5\u001b[0m                  \u001b[1;33m[\u001b[0m\u001b[0mplot_principal_component\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PCA' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "pca = PCA(n_components=3).fit(X)\n",
    "\n",
    "go.Figure(data = [go.Scatter3d(x = X[:, 0], y=X[:, 1], z=X[:, 2], opacity = .75, mode = 'markers', \n",
    "                               marker=dict(size=3, color=\"black\"), showlegend=False)] + \n",
    "                 [plot_principal_component(pca, i) for i in range(3)],\n",
    "          layout = go.Layout(title=r\"$\\text{(1) Original Dataset with PC Components}$\", \n",
    "                             scene = scene, scene_aspectmode=\"cube\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how is the data spread across the three computed PCs, let us project it onto them (Figure 2). To do so let $U\\in\\mathbb{R}^{d\\times k}$ be the matrix with the PCs as columns. As we are currently projecting using all 3 PCs then $U$ is a $3$-by-$3$ orthonormal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10792/4196444404.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_projected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pca' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'pca' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "tmp = deepcopy(pca)\n",
    "tmp.components_ = np.array(pca.transform(pca.components_)).T\n",
    "\n",
    "X_projected = pca.transform(X)\n",
    "go.Figure(data = [go.Scatter3d(x = X_projected[:, 0], y=X_projected[:, 1], z=X_projected[:, 2], opacity = 0.75, \n",
    "                               mode = 'markers', marker=dict(size=3, color=\"black\"), showlegend=False)] + \n",
    "                 [plot_principal_component(tmp, i) for i in range(3)],\n",
    "          layout = go.Layout(scene=proj_scene, scene_aspectmode=\"cube\",\n",
    "                             title=r\"$\\text{(2) Projection Onto PCA Subspace}$\",\n",
    "                             scene_xaxis_title=\"PC1\",\n",
    "                             scene_yaxis_title=\"PC2\",\n",
    "                             scene_zaxis_title=\"PC3\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projection Onto PCA Subspace Of Lower Dimension\n",
    "\n",
    "So we have seen that the PCA algorithm provides us with an orthonormal basis, with a desired properly that the directions correspond with the amount of spread the data shows in that direction.\n",
    "\n",
    "Recall that as the algorithm provided an orthonormal basis then we can represent each sample $\\mathbf{x}_i$ as a linear composition of the columns of $U$: $$ \\mathbf{x}_i = \\sum^d_{j=1} \\langle\\mathbf{x}_i,\\mathbf{u}_j\\rangle \\mathbf{u}_j $$\n",
    "\n",
    "When we project onto the $k<d$ subspace the summation is only using the first $k$ eigenvectors. In matrix notation we compute $\\widetilde{\\mathbf{X}} = U^\\top\\left(\\mathbf{X}U\\right)$ where $U\\in\\mathbb{R}^{d\\times k}$.\n",
    "\n",
    "*For deductive reasons in the code below we take the transformed (projected) data, zero the last dimensions and then perform the multiplication by $U$ using the `inverse_transform` function*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Embedding in a 2D subspace\n",
    "X2d = X_projected.copy()\n",
    "X2d[:, 2] = 0\n",
    "X2d = pca.inverse_transform(X2d)\n",
    "\n",
    "# Enbedding in a 1D subspace\n",
    "X1d = X_projected.copy()\n",
    "X1d[:, [1,2]] = 0\n",
    "X1d = pca.inverse_transform(X1d)\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[r\"$\\text{2D Projection}$\", r\"$\\text{1D Projection}$\"],\n",
    "                    specs=[[{\"type\":\"scatter3d\"}, {\"type\":\"scatter3d\"}]])\n",
    "\n",
    "fig.add_traces([go.Scatter3d(x = X2d[:, 0], y=X2d[:, 1], z=X2d[:, 2], opacity = 0.75, mode = 'markers', marker=dict(size=3, color=\"black\")),\n",
    "                plot_principal_component(pca, 0),\n",
    "                plot_principal_component(pca, 1)], rows=1, cols=1)\n",
    "fig.add_traces([go.Scatter3d(x = X1d[:, 0], y=X1d[:, 1], z=X1d[:, 2], opacity = 0.75, mode = 'markers', marker=dict(size=3, color=\"black\")),\n",
    "                plot_principal_component(pca, 0)], rows=1, cols=2)\n",
    "\n",
    "fig.update_layout(title=r\"$\\text{(3) Projection Onto Lower Dimension Subspace}$\", margin = dict(t = 100), showlegend=False,\n",
    "                  scene=proj_scene, scene2=proj_scene, scene_aspectmode=\"cube\",\n",
    "                  scene_xaxis_title=\"PC1\", scene2_xaxis_title=\"PC1\",\n",
    "                  scene_yaxis_title=\"PC2\", scene2_yaxis_title=\"PC2\",\n",
    "                  scene_zaxis_title=\"PC3\", scene2_zaxis_title=\"PC3\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explained Variance and Singular Values\n",
    "\n",
    "In the parts above, we have linked between the different PCs and how much does the data \"spread\" in each PC direction. This spread is the variance (as in variance of random variables) of the data in the current direction.\n",
    "\n",
    "We have seen that the subspace found by the PCA algorithm is the subspace of some degree $k$ that retains the maximum variance out of all $k$ dimensional subspace. In the proof itself the link between the variance, the principal components and the singular values becomes evident: If we search for a vector onto which we orthogonally project the data and that this vector maximizes the variance of the projected data then:\n",
    " - This vector, which we name as a principal component, is an eigenvector of the sample covariance matrix.\n",
    " - The variance retained by the projection is proportional to the corresponding eigenvalue.\n",
    " - To find the direction with maximum variance we take the first PC to be the eigenvector with the largest eigenvalue.\n",
    "\n",
    "Then, for the next PC we search for a direction in space, satisfying the above but also is perpendicular to the first PC. We continue until we find $k$ PCs.\n",
    "\n",
    "Here, we shall explore this link in an empirical manner, over the loaded datasets. First, let us compute the explained variance. That is, the proportion of variance spread across each PC. As this variance is proportional to the eigenvalues of the sample covariance matrix (which are the singular values of the original data matrix squared) then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "pca = PCA(n_components=3).fit(X)\n",
    "\n",
    "ev = pca.singular_values_**2\n",
    "DataFrame(np.array([ev, ev/sum(ev), pca.explained_variance_ratio_]),\n",
    "          columns=[\"PC 1\", \"PC 2\", \"PC3\"],\n",
    "          index=[\"Eigenvalues\", \"Explained Variance\", \"sklearn's Explained Variance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "variance = list(np.around(100*pca.explained_variance_ratio_, 2)) + [100]\n",
    "\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=[r\"$\\text{Eigenvalues}$\", r\"$\\text{Cumulative Explained Variance}$\"],\n",
    "                    specs=[[{'type': 'Bar'}, {'type': 'Waterfall'}]])\n",
    "\n",
    "fig.add_traces([go.Bar(x=['PC1', 'PC2', 'PC3'], y=pca.singular_values_, marker_color = color_scheme),\n",
    "                go.Waterfall(x=[\"PC1\", \"PC2\", \"PC3\", \"Total\"],\n",
    "                             y=variance,\n",
    "                             text=[f\"{v}%\" for v in variance],\n",
    "                             textposition = \"outside\",\n",
    "                             totals = {\"marker\":{\"color\":\"black\"}},\n",
    "                             measure = [\"relative\", \"relative\", \"relative\", \"total\"])],\n",
    "               rows=[1,1], cols=[1,2])\n",
    "\n",
    "fig.add_shape(type=\"rect\", xref=\"x\", yref=\"y\", x0=-0.4, x1=0.4, y0=0.0, y1=fig.data[1].y[0], \n",
    "              fillcolor=color_scheme[0], line=dict(color=color_scheme[0]), opacity=1,row=1, col=2)\n",
    "fig.add_shape(type=\"rect\", xref=\"x\", yref=\"y\", x0=0.6, x1=1.4, y0=fig.data[1].y[0], y1=fig.data[1].y[0]+fig.data[1].y[1],\n",
    "              fillcolor=color_scheme[1], line=dict(color=color_scheme[1]), opacity=1, row=1, col=2)\n",
    "fig.add_shape(type=\"rect\", xref=\"x\", yref=\"y\", x0=1.6, x1=2.4, y0=fig.data[1].y[0]+fig.data[1].y[1], y1=fig.data[1].y[0]+fig.data[1].y[1]+fig.data[1].y[2], \n",
    "              fillcolor=color_scheme[2], line=dict(color=color_scheme[2]), opacity=1, row=1, col=2)\n",
    "\n",
    "fig.update_layout(showlegend=False, title=r\"$\\text{(4) PCA Explained Variance}$\", margin=dict(t=100))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time To Think...\n",
    "After investigative both simulated datasets with a variety of settings let us focus on the real-world dataset. \n",
    "\n",
    "Consider figures 1,2 and 4 and think:\n",
    "- Looking at Figure 1, can we imagine some low dimension subspace that fits the data? What would be the dimension of such a subspace? \n",
    "- Does the representation of the data in the PCs basis in Figure 2 support or contradict your answer regarding Figure 1? (Pay attention to the scales of the PC axes. To make things clearer you are encouraged to change the `proj_scene` variable relevant to this dataset.)\n",
    "- How does the explained variance relate to the conclusions above? Based on Figure 4, what would you choose as the dimension of the embedded subspace? Is this in agreement with your previous answers?\n",
    "\n",
    "Lastly, using this real-world example but considering PCA as a general algorithm: in terms of model interperability, do the PCs help us infer anything regarding the original features? For example, suppose 90% of the explained variance is captured by the first PC, does it tell us how significant was the first feature? Does it tell us how significant any individual feature is? How would we be able to interprate relevance of features based on the projection or coordinates given by the PCA algorithm?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-root-py",
   "language": "python",
   "display_name": "Python [conda env:root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}